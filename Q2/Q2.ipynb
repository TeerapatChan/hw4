{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5sc65O68oPNN"
      },
      "source": [
        "# DVA HW4 Q2"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "63EwvRRwocM9"
      },
      "source": [
        "Do not distribute or publish this code\n",
        "\n",
        "Do not change the **#export** statements or add and other code or comments above them. They are needed for grading."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "metadata": {
        "id": "uD5u3XBgn_zs"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "'''\n",
        "*** Imports ***\n",
        "    DO NOT EDIT or add anything to this section\n",
        "'''\n",
        "import csv\n",
        "import numpy as np  # http://www.numpy.org\n",
        "import ast\n",
        "from datetime import datetime\n",
        "from math import log, floor, ceil\n",
        "import random"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "jMF-xgsFpB67"
      },
      "source": [
        "## Update 'Utility' class"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "JJlOKaA7n_zt"
      },
      "source": [
        "Modify the Utility class's methods. You can also add additional methods as required but don't change existing methods' arguments."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EAfcIKlAn_zt"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class Utility(object):\n",
        "\n",
        "    # This method computes entropy for information gain\n",
        "    def entropy(self, class_y):\n",
        "        # Input:\n",
        "        #   class_y         : list of class labels (0's and 1's)\n",
        "\n",
        "        if len(class_y) == 0:\n",
        "            return 0\n",
        "\n",
        "        p1 = class_y.count(1) / len(class_y)\n",
        "        p0 = class_y.count(0) / len(class_y)\n",
        "        entropy = 0\n",
        "\n",
        "        if p1 > 0:\n",
        "            entropy -= p1 * log(p1)\n",
        "        if p0 > 0:\n",
        "            entropy -= p0 * log(p0)\n",
        "\n",
        "        return entropy\n",
        "\n",
        "\n",
        "    def partition_classes(self, X, y, split_attribute, split_val):\n",
        "        # Inputs:\n",
        "        #   X               : data containing all attributes\n",
        "        #   y               : labels\n",
        "        #   split_attribute : column index of the attribute to split on\n",
        "        #   split_val       : a numerical value to divide the split_attribute\n",
        "\n",
        "        X_left, X_right, y_left, y_right = [], [], [], []\n",
        "\n",
        "        for i in range(len(X)):\n",
        "            if X[i][split_attribute] <= split_val:\n",
        "                X_left.append(X[i])\n",
        "                y_left.append(y[i])\n",
        "            else:\n",
        "                X_right.append(X[i])\n",
        "                y_right.append(y[i])\n",
        "\n",
        "        return (X_left, X_right, y_left, y_right)\n",
        "\n",
        "\n",
        "    def information_gain(self, previous_y, current_y):\n",
        "        # Inputs:\n",
        "        #   previous_y: the distribution of original labels (0's and 1's)\n",
        "        #   current_y:  the distribution of labels after splitting based on a particular\n",
        "        #               split attribute and split value\n",
        "        n_parent = len(previous_y)\n",
        "        if n_parent == 0:\n",
        "            return 0\n",
        "        parent_entropy = self.entropy(previous_y)\n",
        "\n",
        "        weighted_child_entropy = 0\n",
        "        for child_y in current_y:\n",
        "            weight = len(child_y) / n_parent\n",
        "            weighted_child_entropy += weight * self.entropy(child_y)\n",
        "\n",
        "        info_gain = parent_entropy - weighted_child_entropy\n",
        "\n",
        "        return info_gain\n",
        "\n",
        "    def best_split(self, X, y):\n",
        "        # Inputs:\n",
        "        #   X       : Data containing all attributes\n",
        "        #   y       : labels\n",
        "        #   TODO    : For each node find the best split criteria and return the split attribute,\n",
        "        #             spliting value along with  X_left, X_right, y_left, y_right (using partition_classes)\n",
        "        #             in the dictionary format {'split_attribute':split_attribute, 'split_val':split_val,\n",
        "        #             'X_left':X_left, 'X_right':X_right, 'y_left':y_left, 'y_right':y_right, 'info_gain':info_gain}\n",
        "\n",
        "        best_split = {\n",
        "            'split_attribute': None,\n",
        "            'split_val': None,\n",
        "            'X_left': [],\n",
        "            'X_right': [],\n",
        "            'y_left': [],\n",
        "            'y_right': [],\n",
        "            'info_gain': -1\n",
        "        }\n",
        "\n",
        "        if len(X) == 0:\n",
        "            return best_split\n",
        "\n",
        "        n_features = len(X[0])\n",
        "\n",
        "        # Try every feature and every unique value as a possible split\n",
        "        for feature in range(n_features):\n",
        "            values = sorted(set([row[feature] for row in X]))\n",
        "\n",
        "            for val in values:\n",
        "                X_left, X_right, y_left, y_right = self.partition_classes(X, y, feature, val)\n",
        "                if len(y_left) == 0 or len(y_right) == 0:\n",
        "                    continue\n",
        "\n",
        "                gain = self.information_gain(y, [y_left, y_right])\n",
        "\n",
        "                if gain > best_split['info_gain']:\n",
        "                    best_split = {\n",
        "                        'split_attribute': feature,\n",
        "                        'split_val': val,\n",
        "                        'X_left': X_left,\n",
        "                        'X_right': X_right,\n",
        "                        'y_left': y_left,\n",
        "                        'y_right': y_right,\n",
        "                        'info_gain': gain\n",
        "                    }\n",
        "\n",
        "        return best_split"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "5xITJYXln_zu"
      },
      "source": [
        "## Update the 'DecisionTree' and 'RandomForest' classes"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "eZkW-Qk7n_zu"
      },
      "source": [
        "Please modify the 'DecisionTree' and 'RandomForest' classes below"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "WEheMuC3n_zu"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "class DecisionTree(object):\n",
        "    def __init__(self, max_depth):\n",
        "        # Initializing the tree as an empty dictionary or list, as preferred\n",
        "        self.tree = {}\n",
        "        self.max_depth = max_depth\n",
        "        self.util = Utility() # Instantiate Utility class\n",
        "\n",
        "    def _create_leaf(self, y):\n",
        "        \"\"\"Helper function to create a leaf node (predict majority class).\"\"\"\n",
        "        if not y:\n",
        "            return 0\n",
        "        \n",
        "        ones = sum(y)\n",
        "        zeros = len(y) - ones\n",
        "        \n",
        "        return 1 if ones > zeros else 0\n",
        "\n",
        "    def learn(self, X, y, par_node = None, depth=0):\n",
        "        # Set the root node on the first call\n",
        "        if depth == 0:\n",
        "            par_node = self.tree\n",
        "            \n",
        "        # 1. If no data/labels, create a default leaf\n",
        "        if not y:\n",
        "            par_node['leaf_val'] = 0 # Default to 0\n",
        "            return\n",
        "\n",
        "        # 2. If all labels are the same\n",
        "        if len(set(y)) == 1:\n",
        "            par_node['leaf_val'] = y[0]\n",
        "            return\n",
        "\n",
        "        # 3. If max depth is reached\n",
        "        if depth == self.max_depth:\n",
        "            par_node['leaf_val'] = self._create_leaf(y)\n",
        "            return\n",
        "\n",
        "        # 4. Find the best split\n",
        "        split_details = self.util.best_split(X, y)\n",
        "\n",
        "        # 5. If no good split found (no info gain or empty data)\n",
        "        if not split_details or split_details['info_gain'] <= 0:\n",
        "            par_node['leaf_val'] = self._create_leaf(y)\n",
        "            return\n",
        "\n",
        "        # 6. Populate the current node with split info\n",
        "        par_node['split_attribute'] = split_details['split_attribute']\n",
        "        par_node['split_val'] = split_details['split_val']\n",
        "        \n",
        "        # 7. Create left and right child nodes\n",
        "        par_node['left'] = {}\n",
        "        par_node['right'] = {}\n",
        "        \n",
        "        # 8. Recursive\n",
        "        self.learn(split_details['X_left'], \n",
        "                   split_details['y_left'], \n",
        "                   par_node['left'], \n",
        "                   depth + 1)\n",
        "        \n",
        "        self.learn(split_details['X_right'], \n",
        "                   split_details['y_right'], \n",
        "                   par_node['right'], \n",
        "                   depth + 1)\n",
        "\n",
        "    def classify(self, record):\n",
        "        node = self.tree\n",
        "        \n",
        "        while True:\n",
        "            if 'leaf_val' in node:\n",
        "                return node['leaf_val']\n",
        "            \n",
        "            if 'split_attribute' not in node:\n",
        "                return 0\n",
        "            \n",
        "            attr = node['split_attribute']\n",
        "            val = node['split_val']\n",
        "            \n",
        "            if record[attr] <= val:\n",
        "                node = node['left']\n",
        "            else:\n",
        "                node = node['right']\n",
        "                \n",
        "            if not node:\n",
        "                return 0"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "metadata": {
        "id": "cnmeoxynn_zu"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "# This starter code does not run. You will have to add your changes and\n",
        "# turn in code that runs properly.\n",
        "\n",
        "\"\"\"\n",
        "Here,\n",
        "1. X is assumed to be a matrix with n rows and d columns where n is the\n",
        "number of total records and d is the number of features of each record.\n",
        "2. y is assumed to be a vector of labels of length n.\n",
        "3. XX is similar to X, except that XX also contains the data label for each\n",
        "record.\n",
        "\"\"\"\n",
        "\n",
        "\"\"\"\n",
        "This skeleton is provided to help you implement the assignment.You must\n",
        "implement the existing functions as necessary. You may add new functions\n",
        "as long as they are called from within the given classes.\n",
        "\n",
        "VERY IMPORTANT!\n",
        "Do NOT change the signature of the given functions.\n",
        "Do NOT change any part of the main function APART from the forest_size parameter.\n",
        "\"\"\"\n",
        "\n",
        "\n",
        "class RandomForest(object):\n",
        "    num_trees = 0\n",
        "    decision_trees = []\n",
        "\n",
        "    # the bootstrapping datasets for trees\n",
        "    # bootstraps_datasets is a list of lists, where each list in bootstraps_datasets is a bootstrapped dataset.\n",
        "    bootstraps_datasets = []\n",
        "\n",
        "    # the true class labels, corresponding to records in the bootstrapping datasets\n",
        "    # bootstraps_labels is a list of lists, where the 'i'th list contains the labels corresponding to records in\n",
        "    # the 'i'th bootstrapped dataset.\n",
        "    bootstraps_labels = []\n",
        "\n",
        "    def __init__(self, num_trees):\n",
        "        # Initialization done here\n",
        "        self.num_trees = num_trees\n",
        "        self.decision_trees = [DecisionTree(max_depth=10) for i in range(num_trees)]\n",
        "        self.bootstraps_datasets = []\n",
        "        self.bootstraps_labels = []\n",
        "\n",
        "    def _bootstrapping(self, XX, n):\n",
        "        sample = [] # sampled dataset\n",
        "        labels = []  # class labels for the sampled records\n",
        "\n",
        "        total_size = len(XX)\n",
        "        for _ in range(n):\n",
        "            record = XX[random.randint(0, total_size - 1)]\n",
        "            \n",
        "            sample.append(record[:-1])\n",
        "            labels.append(record[-1])\n",
        "\n",
        "        return (sample, labels)\n",
        "\n",
        "    def bootstrapping(self, XX):\n",
        "        # Initializing the bootstap datasets for each tree\n",
        "        for _ in range(self.num_trees):\n",
        "            data_sample, data_label = self._bootstrapping(XX, len(XX))\n",
        "            self.bootstraps_datasets.append(data_sample)\n",
        "            self.bootstraps_labels.append(data_label)\n",
        "\n",
        "    def fitting(self):\n",
        "        for i in range(self.num_trees):\n",
        "            X = self.bootstraps_datasets[i]\n",
        "            y = self.bootstraps_labels[i]\n",
        "            tree = self.decision_trees[i]\n",
        "            \n",
        "            tree.learn(X, y)\n",
        "\n",
        "    def voting(self, X):\n",
        "        y = []\n",
        "\n",
        "        for record in X:\n",
        "            votes = []\n",
        "\n",
        "            for i in range(len(self.bootstraps_datasets)):\n",
        "                dataset = self.bootstraps_datasets[i]\n",
        "\n",
        "                # 1. Check if the record is OOB for this tree\n",
        "                if record not in dataset:\n",
        "                    # 2. Get prediction from the OOB tree\n",
        "                    OOB_tree = self.decision_trees[i]\n",
        "                    effective_vote = OOB_tree.classify(record)\n",
        "                    votes.append(int(effective_vote))\n",
        "\n",
        "            # 3. Tally votes\n",
        "            if not votes:\n",
        "                # fallback: use all trees\n",
        "                fallback_votes = [int(tree.classify(record)) for tree in self.decision_trees]\n",
        "                if not fallback_votes:\n",
        "                    y.append(0)\n",
        "                else:\n",
        "                    counts = {}\n",
        "                    for v in fallback_votes:\n",
        "                        counts[v] = counts.get(v, 0) + 1\n",
        "                    y.append(max(counts, key=counts.get))\n",
        "            else:\n",
        "                counts = {}\n",
        "                for v in votes:\n",
        "                    counts[v] = counts.get(v, 0) + 1\n",
        "                y.append(max(counts, key=counts.get))\n",
        "\n",
        "        return y\n",
        "\n",
        "    def user(self):\n",
        "        \"\"\"\n",
        "        :return: string\n",
        "        your GTUsername, NOT your 9-Digit GTId\n",
        "        \"\"\"\n",
        "        return 'npallapangkul3'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "metadata": {
        "id": "LpMChIARn_zu"
      },
      "outputs": [],
      "source": [
        "#export\n",
        "\n",
        "# TODO: Determine the forest size according to your implementation.\n",
        "# This function will be used by the autograder to set your forest size during testing\n",
        "# VERY IMPORTANT: Minimum forest_size should be 10\n",
        "def get_forest_size():\n",
        "    forest_size = 10\n",
        "    return forest_size\n",
        "\n",
        "# TODO: Determine random seed to set for reproducibility\n",
        "# This function will be used by the autograder to set the random seed to obtain the same results you achieve locally\n",
        "def get_random_seed():\n",
        "    random_seed = 555\n",
        "    return random_seed"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qJLEiqrKn_zu"
      },
      "source": [
        "## Do not modify the below cell\n",
        "The cell below is provided to test that your random forest classifier can be successfully built and run. Similar steps will be used to build and run your code in Gradescope. Any additional testing of functions can be done in the cells below the `run()` cell, as these will not be parsed by the autograder."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 41,
      "metadata": {
        "id": "VxPPVN8dn_zu"
      },
      "outputs": [],
      "source": [
        "def run():\n",
        "    np.random.seed(get_random_seed())\n",
        "    # start time\n",
        "    start = datetime.now()\n",
        "    X = list()\n",
        "    y = list()\n",
        "    XX = list()  # Contains data features and data labels\n",
        "    numerical_cols = set([i for i in range(0, 31)])  # indices of numeric attributes (columns)\n",
        "\n",
        "    # Loading data set\n",
        "    print(\"reading the data\")\n",
        "    with open(\"Wisconsin_breast_prognostic.csv\") as f:\n",
        "        next(f, None)\n",
        "        for line in csv.reader(f, delimiter=\",\"):\n",
        "            xline = []\n",
        "            for i in range(len(line)):\n",
        "                if i in numerical_cols:\n",
        "                    xline.append(ast.literal_eval(line[i]))\n",
        "                else:\n",
        "                    xline.append(line[i])\n",
        "\n",
        "            X.append(xline[:-1])\n",
        "            y.append(xline[-1])\n",
        "            XX.append(xline[:])\n",
        "\n",
        "    # Initializing a random forest.\n",
        "    randomForest = RandomForest(get_forest_size())\n",
        "\n",
        "    # printing the name\n",
        "    print(\"__Name: \" + randomForest.user()+\"__\")\n",
        "\n",
        "    # Creating the bootstrapping datasets\n",
        "    print(\"creating the bootstrap datasets\")\n",
        "    randomForest.bootstrapping(XX)\n",
        "\n",
        "    # Building trees in the forest\n",
        "    print(\"fitting the forest\")\n",
        "    randomForest.fitting()\n",
        "\n",
        "    # Calculating an unbiased error estimation of the random forest\n",
        "    # based on out-of-bag (OOB) error estimate.\n",
        "    y_predicted = randomForest.voting(X)\n",
        "\n",
        "    # Comparing predicted and true labels\n",
        "    results = [prediction == truth for prediction, truth in zip(y_predicted, y)]\n",
        "\n",
        "    # Accuracy\n",
        "    accuracy = float(results.count(True)) / float(len(results))\n",
        "\n",
        "    print(\"accuracy: %.4f\" % accuracy)\n",
        "    print(\"OOB estimate: %.4f\" % (1 - accuracy))\n",
        "\n",
        "    # end time\n",
        "    print(\"Execution time: \" + str(datetime.now() - start))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 42,
      "metadata": {
        "id": "IaK7xdjNn_zv"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "reading the data\n",
            "__Name: npallapangkul3__\n",
            "creating the bootstrap datasets\n",
            "fitting the forest\n",
            "accuracy: 0.9315\n",
            "OOB estimate: 0.0685\n",
            "Execution time: 0:00:16.840306\n"
          ]
        }
      ],
      "source": [
        "# Call the run() function to test your implementation\n",
        "# Use this cell and any cells below for additional testing\n",
        "run()"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": ".venv",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.13.1"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
